import{f as I,j as A}from"./chunk-ANHI7V3N.js";import{a as k,b as H,c as O,d as F,e as L}from"./chunk-LPGHQU2X.js";import{a as P,c as D,h as S}from"./chunk-U576KP6F.js";import{L as _,N as E,O as M,Q as w,S as C,T}from"./chunk-DL77DU4H.js";import{Ma as c,Na as g,Ob as n,Pa as a,Pb as d,Rb as v,Sb as y,Y as m,ab as u,bb as h,sb as f,tb as x,ub as b,vb as s,wb as t,xb as e,yb as l}from"./chunk-KVGSNQX3.js";var z=(()=>{class o{static \u0275fac=function(i){return new(i||o)};static \u0275mod=h({type:o});static \u0275inj=m({})}return o})();var R=(()=>{class o{static \u0275fac=function(i){return new(i||o)};static \u0275mod=h({type:o});static \u0275inj=m({imports:[_,z,I]})}return o})();function Q(o,p){if(o&1&&(t(0,"a",10),n(1),e()),o&2){let r=p.$implicit;s("href",y(r.url),g),a(),d(r.name)}}function V(o,p){if(o&1&&(t(0,"a",10),n(1),e()),o&2){let r=p.$implicit;s("href",y(r.url),g),a(),d(r.name)}}var j=class o{experiment={name:"Unilateral Motor Imagery",description:"This experiment focuses on the <b>mental rehearsal of movement</b> involving a <b>single limb</b>\u2014typically the left or right hand\u2014without any actual muscular activity. It is designed to evaluate a participant\u2019s ability to generate <b>consistent</b> and <b>classifiable brain signals</b> through motor imagery alone. <b>Unilateral motor imagery</b> is widely used in <b>brain-computer interface (BCI) research</b> due to its simplicity, <b>clear cortical activation patterns</b>, and effectiveness in training <b>decoding algorithms</b>.",metadata:{type:"Unilateral",paradigm:"Endogenous",stimulus_type:"Visual",recording_modality:"EEG",difficulty_level:"Moderate",class_range:{min:2,max:4},intended_applications:[{name:"Rehabilitation",url:"/applications/rehabilitation"},{name:"BCI Training",url:"/applications/bci-training"},{name:"Prosthetics",url:"/applications/prosthetics"}],common_datasets:[{name:"BCI Competition IV 2a",url:"/datasets/bci-competition-iv-2a"},{name:"PhysioNet EEG Motor Imagery",url:"/datasets/physionet-eeg-mi"}]},objective:"The main objective of this experiment is to assess the capability of individuals to voluntarily modulate their <b>sensorimotor rhythms (SMRs)</b> through the imagined movement of a <b>single limb</b>, typically the <b>left or right hand</b>. By focusing on <b>unilateral motor imagery</b>, the protocol aims to isolate specific <b>cortical activation patterns</b> that can be detected using <b>non-invasive brain recording techniques</b> such as <b>EEG</b>. These patterns are then used to evaluate the feasibility of <b>decoding motor intentions</b> for <b>brain-computer interface (BCI)</b> applications.",hypothesis:"We hypothesize that <b>unilateral motor imagery</b>\u2014specifically the imagined movement of a <b>single hand</b>\u2014produces <b>distinguishable</b> and <b>repeatable changes</b> in the <b>mu and beta frequency bands</b> over <b>sensorimotor cortex</b>. These changes can be reliably detected through <b>EEG</b> and used to <b>classify mental states</b> corresponding to <b>left or right hand motor imagery</b>, supporting the development of <b>accurate and robust BCI control strategies</b>.",procedure:"Participants are seated comfortably in a <b>controlled environment</b> and fitted with <b>EEG equipment</b>. Each trial begins with a <b>fixation cross</b> displayed at the center of the screen, followed by a <b>visual cue</b> (such as an arrow) indicating which hand the participant should imagine moving. The participant is instructed to <b>imagine performing the movement</b> (e.g., grasping or rotating the hand) <b>without any actual muscle contraction</b>. Each imagery period typically lasts between <b>4 to 6 seconds</b> and is followed by a <b>rest interval</b>. The protocol is repeated across <b>multiple trials</b> to ensure sufficient data for analysis. The entire session lasts approximately <b>20 to 40 minutes</b> depending on the number of classes and blocks.",requirements:"This experiment requires access to a <b>modern web browser</b> capable of rendering visual stimuli with <b>precise timing</b> (e.g., Chrome or Firefox). For experimental use with EEG systems, the platform must support <b>synchronized stimulus presentation</b> and integration with <b>external acquisition hardware</b> via <b>serial, WebUSB</b>, or <b>network-based protocols</b>. Participants should be instructed on <b>motor imagery techniques</b> and perform the task in a <b>quiet, distraction-free environment</b>. Optional features include <b>online feedback interfaces</b> and <b>real-time monitoring tools</b> for data quality assessment.",characteristics:"This experiment is classified as <b>endogenous</b> because it relies entirely on the participant\u2019s <b>internal cognitive processes</b>\u2014specifically <b>voluntary mental imagery</b>\u2014to generate the desired neural activity. It is considered <b>unilateral</b> because only one limb (either the left or the right hand) is imagined per trial, allowing for <b>clearer separation</b> of cortical activation and <b>simplified classification</b> of motor intentions within brain-computer interface systems."};escapeHtml(p){let r=document.createElement("p");return r.innerText=p,r.innerHTML}static \u0275fac=function(r){return new(r||o)};static \u0275cmp=u({type:o,selectors:[["app-experiment"]],inputs:{experiment:"experiment"},decls:77,vars:14,consts:[[1,"page-container"],[1,"no-margin-bottom"],[1,"align-justify",3,"innerHTML"],["matFab","","extended","",1,"button-configure"],["appearance","outlined",1,"margin-top-small"],[1,"grid-responsive-3"],["matListItemTitle",""],["matListItemLine",""],[1,"grid-responsive-2"],[1,"button-wrapper"],["matButton","","target","_blank",3,"href"]],template:function(r,i){r&1&&(t(0,"div",0)(1,"h2",1),n(2),e(),l(3,"p",2),t(4,"button",3)(5,"mat-icon"),n(6,"build"),e(),n(7," Configure this experiment "),e(),t(8,"mat-card",4)(9,"mat-card-content")(10,"mat-list")(11,"div",5)(12,"mat-list-item")(13,"span",6),n(14,"Task Laterality:"),e(),t(15,"span",7),n(16),e()(),t(17,"mat-list-item")(18,"span",6),n(19,"Paradigm:"),e(),t(20,"span",7),n(21),e()(),t(22,"mat-list-item")(23,"span",6),n(24,"Stimulus Type:"),e(),t(25,"span",7),n(26),e()(),t(27,"mat-list-item")(28,"span",6),n(29,"Recording Modality:"),e(),t(30,"span",7),n(31),e()(),t(32,"mat-list-item")(33,"span",6),n(34,"Difficulty Level:"),e(),t(35,"span",7),n(36),e()(),t(37,"mat-list-item")(38,"span",6),n(39,"Classes:"),e(),t(40,"span",7),n(41),e()()()(),t(42,"mat-list")(43,"div",8)(44,"mat-list-item",9)(45,"span",6),n(46,"Intended Applications:"),e(),t(47,"span",7),x(48,Q,2,3,"a",10,f),e()(),t(50,"mat-list-item",9)(51,"span",6),n(52,"Common Datasets:"),e(),t(53,"span",7),x(54,V,2,3,"a",10,f),e()()()()()(),t(56,"div",8)(57,"div")(58,"h4",1),n(59,"Objective"),e(),l(60,"p",2),e(),t(61,"div")(62,"h4",1),n(63,"Hypothesis"),e(),l(64,"p",2),e(),t(65,"div")(66,"h4",1),n(67,"Procedure"),e(),l(68,"p",2),e(),t(69,"div")(70,"h4",1),n(71,"Requirements"),e(),l(72,"p",2),e()(),t(73,"div")(74,"h4",1),n(75,"Cognitive Task Characteristics"),e(),l(76,"p",2),e()()),r&2&&(a(2),d(i.experiment.name),a(),s("innerHTML",i.experiment.description,c),a(13),d(i.experiment.metadata.type),a(5),d(i.experiment.metadata.paradigm),a(5),d(i.experiment.metadata.stimulus_type),a(5),d(i.experiment.metadata.recording_modality),a(5),d(i.experiment.metadata.difficulty_level),a(5),v("",i.experiment.metadata.class_range.min," up to ",i.experiment.metadata.class_range.max),a(7),b(i.experiment.metadata.intended_applications),a(6),b(i.experiment.metadata.common_datasets),a(6),s("innerHTML",i.experiment.objective,c),a(4),s("innerHTML",i.experiment.hypothesis,c),a(4),s("innerHTML",i.experiment.procedure,c),a(4),s("innerHTML",i.experiment.requirements,c),a(4),s("innerHTML",i.experiment.characteristics,c))},dependencies:[L,O,F,H,k,w,E,M,S,P,D,T,C,A,R],styles:["span[matListItemLine][_ngcontent-%COMP%]{color:var(--mat-sys-primary)}mat-list-item.button-wrapper[_ngcontent-%COMP%]{height:100%}.button-wrapper[_ngcontent-%COMP%]   a[matButton][_ngcontent-%COMP%]{margin-top:4px}.button-configure[_ngcontent-%COMP%]{margin-bottom:16px;box-shadow:var(--mat-sys-level2)}"]})};export{j as a};
